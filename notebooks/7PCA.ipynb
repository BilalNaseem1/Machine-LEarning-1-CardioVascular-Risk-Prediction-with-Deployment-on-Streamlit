{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXJr8wMRmlw0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "from scipy.stats import ttest_1samp, shapiro\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "from sklearn.metrics import recall_score, make_scorer, roc_auc_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "from graphviz import Source\n",
        "from sklearn.tree import export_graphviz\n",
        "from sklearn import tree\n",
        "from IPython.display import SVG, display\n",
        "# import shap\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from scipy.stats.mstats import winsorize\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzP5c3MKmpuy",
        "outputId": "eea10da3-b370-47e4-f8f3-18b7aeec4cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying PCA on Original"
      ],
      "metadata": {
        "id": "wfO6OIZFm7Z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/ml1_final_project/data_cardiovascular_risk.csv')\n",
        "columns_to_convert = ['sex', 'education', 'is_smoking', 'BPMeds', 'prevalentStroke', 'prevalentHyp', 'diabetes', 'TenYearCHD']\n",
        "df[columns_to_convert] = df[columns_to_convert].astype('object')\n",
        "categorical_columns = df.select_dtypes(include='object').columns\n",
        "numerical_columns = df.select_dtypes(include=['float', 'int']).columns\n",
        "\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "# Remove rows where 'bpmeds' column is null\n",
        "df = df.dropna(subset=['BPMeds'])\n",
        "\n",
        "imputing_median1 = df[df['is_smoking'] == 'YES']['cigsPerDay'].median()\n",
        "df['cigsPerDay'] = df['cigsPerDay'].fillna(imputing_median1)\n",
        "\n",
        "\n",
        "# Dropping the 3 Columns #######################################################\n",
        "df.drop('id', axis=1, inplace=True)\n",
        "df.drop('education', axis=1, inplace=True)\n",
        "df.drop(['is_smoking', 'prevalentStroke'], axis=1, inplace=True)\n",
        "##################################################################################\n",
        "\n",
        "for var in ['totChol', 'BMI', 'heartRate']:\n",
        "  imputer = IterativeImputer(random_state=0)\n",
        "  df[[var]] = imputer.fit_transform(df[[var]])\n",
        "\n",
        "\n",
        "# fit and transform the imputer on your data\n",
        "imputer = IterativeImputer(random_state = 0)\n",
        "imputer.fit(df[['glucose']])\n",
        "\n",
        "df[['glucose']] = imputer.transform(df[['glucose']])\n",
        "\n",
        "\n",
        "##### New Feature meanBP\n",
        "# Create a new feature 'mean_BP' as the mean of 'sysBP' and 'diaBP'\n",
        "df['mean_BP'] = (df['sysBP'] + df['diaBP']) / 2\n",
        "\n",
        "# Drop the 'sysBP' and 'diaBP' columns\n",
        "df.drop(['sysBP', 'diaBP'], axis=1, inplace=True)\n",
        "###########\n",
        "\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "X = df.drop(['TenYearCHD_1'], axis = 1)\n",
        "y = df['TenYearCHD_1']\n",
        "\n",
        "X_winsorized = X.copy()\n",
        "\n",
        "\n",
        "# Apply winsorization to each column with the optimal limits\n",
        "X_winsorized = X.copy()\n",
        "\n",
        "X_winsorized['age'] = winsorize(X_winsorized['age'], limits=(0, 0))\n",
        "X_winsorized['cigsPerDay'] = winsorize(X_winsorized['cigsPerDay'], limits=(0.7, 0.01))\n",
        "X_winsorized['totChol'] = winsorize(X_winsorized['totChol'], limits=(0, 0))\n",
        "# X_winsorized['sysBP'] = winsorize(X_winsorized['sysBP'], limits=(0, 0))\n",
        "# X_winsorized['diaBP'] = winsorize(X_winsorized['diaBP'], limits=(0.8, 0))\n",
        "X_winsorized['mean_BP'] = winsorize(X_winsorized['mean_BP'], limits=(0, 0))\n",
        "X_winsorized['BMI'] = winsorize(X_winsorized['BMI'], limits=(0, 0))\n",
        "X_winsorized['heartRate'] = winsorize(X_winsorized['heartRate'], limits=(0, 0))\n",
        "X_winsorized['glucose'] = winsorize(X_winsorized['glucose'], limits=(0.7, 0.2))\n",
        "X_winsorized['sex_M'] = winsorize(X_winsorized['sex_M'], limits=(0, 0))\n",
        "X_winsorized['BPMeds_1.0'] = winsorize(X_winsorized['BPMeds_1.0'], limits=(0, 0))\n",
        "X_winsorized['prevalentHyp_1'] = winsorize(X_winsorized['prevalentHyp_1'], limits=(0, 0.4))\n",
        "X_winsorized['diabetes_1'] = winsorize(X_winsorized['diabetes_1'], limits=(0, 0))\n",
        "\n",
        "\n",
        "#################################################################################\n",
        "# Create an instance of PCA\n",
        "pca = PCA(n_components=8)  # Set the number of components (dimensions) you want to keep\n",
        "\n",
        "# Fit the PCA model to your data\n",
        "pca.fit(X_winsorized)\n",
        "\n",
        "# Transform the data to the lower-dimensional space\n",
        "X_pca = pca.transform(X_winsorized)\n",
        "###################################################################################\n",
        "\n",
        "# Split the winsorized data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train_s = scaler.fit_transform(X_train)\n",
        "X_test_s = scaler.transform(X_test)\n",
        "\n",
        "# Train Gaussian Naive Bayes\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train_s, y_train)\n",
        "\n",
        "# Make predictions and calculate AUC\n",
        "y_pred = gnb.predict_proba(X_test_s)[:, 1]\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "# Print the AUC score\n",
        "print(\"AUC:\", auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDKnH1m3msNL",
        "outputId": "f0c29fd7-df24-41a6-dd9f-0e554c2855bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: 0.737537757437071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_winsorized.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehVAEV15nWgy",
        "outputId": "d1b4aa39-6c05-47d5-e739-1fc17019092f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3346, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fvkWUwndncwZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}