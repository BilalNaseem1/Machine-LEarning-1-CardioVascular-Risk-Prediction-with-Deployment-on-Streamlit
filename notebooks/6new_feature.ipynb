{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pwtZjWcjNpd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "from scipy.stats import ttest_1samp, shapiro\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "from sklearn.metrics import recall_score, make_scorer, roc_auc_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "from graphviz import Source\n",
        "from sklearn.tree import export_graphviz\n",
        "from sklearn import tree\n",
        "from IPython.display import SVG, display\n",
        "# import shap\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from scipy.stats.mstats import winsorize\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import PowerTransformer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wo-06qFUjt8Q",
        "outputId": "e5ff47b0-1b83-4d36-9ffd-9005fb1aba72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/ml1_final_project/data_cardiovascular_risk.csv')\n",
        "columns_to_convert = ['sex', 'education', 'is_smoking', 'BPMeds', 'prevalentStroke', 'prevalentHyp', 'diabetes', 'TenYearCHD']\n",
        "df[columns_to_convert] = df[columns_to_convert].astype('object')\n",
        "categorical_columns = df.select_dtypes(include='object').columns\n",
        "numerical_columns = df.select_dtypes(include=['float', 'int']).columns\n",
        "\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "# Remove rows where 'bpmeds' column is null\n",
        "df = df.dropna(subset=['BPMeds'])\n",
        "\n",
        "imputing_median1 = df[df['is_smoking'] == 'YES']['cigsPerDay'].median()\n",
        "df['cigsPerDay'] = df['cigsPerDay'].fillna(imputing_median1)\n",
        "\n",
        "df.drop('id', axis=1, inplace=True)\n",
        "df.drop('education', axis=1, inplace=True)\n",
        "df.drop(['is_smoking', 'prevalentStroke'], axis=1, inplace=True)\n",
        "\n",
        "for var in ['totChol', 'BMI', 'heartRate']:\n",
        "  imputer = IterativeImputer(random_state=0)\n",
        "  df[[var]] = imputer.fit_transform(df[[var]])\n",
        "\n",
        "\n",
        "# fit and transform the imputer on your data\n",
        "imputer = IterativeImputer(random_state = 0)\n",
        "imputer.fit(df[['glucose']])\n",
        "\n",
        "df[['glucose']] = imputer.transform(df[['glucose']])\n",
        "\n",
        "\n",
        "##### New Feature meanBP\n",
        "# Create a new feature 'mean_BP' as the mean of 'sysBP' and 'diaBP'\n",
        "df['mean_BP'] = (df['sysBP'] + df['diaBP']) / 2\n",
        "\n",
        "# Drop the 'sysBP' and 'diaBP' columns\n",
        "df.drop(['sysBP', 'diaBP'], axis=1, inplace=True)\n",
        "###########\n",
        "\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "X = df.drop(['TenYearCHD_1'], axis = 1)\n",
        "y = df['TenYearCHD_1']\n",
        "\n",
        "X_winsorized = X.copy()\n",
        "\n",
        "from scipy.stats.mstats import winsorize\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Define the range of winsorizing limits to try\n",
        "lower_limits_range = [0, 0.01, 0.05, 0.1, 0.15, 0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95]\n",
        "upper_limits_range = [0, 0.01, 0.05, 0.1, 0.15, 0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95]\n",
        "\n",
        "# Initialize variables to store the optimal limits and corresponding AUC score\n",
        "optimal_limits = {}\n",
        "optimal_auc = 0\n",
        "\n",
        "# Iterate over the columns\n",
        "for column in X.columns:\n",
        "    # Initialize variables to store the optimal lower and upper limits for the current column\n",
        "    optimal_lower_limit = 0\n",
        "    optimal_upper_limit = 0\n",
        "    \n",
        "    # Iterate over the lower limits range\n",
        "    for lower_limit in lower_limits_range:\n",
        "        # Iterate over the upper limits range\n",
        "        for upper_limit in upper_limits_range:\n",
        "            # Apply winsorizing on the column with the current lower and upper limits\n",
        "            X_winsorized = X.copy()\n",
        "            X_winsorized[column] = winsorize(X_winsorized[column], limits=(lower_limit, upper_limit))\n",
        "        \n",
        "            # Split the winsorized data into training and testing sets\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X_winsorized, y, test_size=0.2, random_state=42)\n",
        "        \n",
        "            # Train Gaussian Naive Bayes\n",
        "            gnb = GaussianNB()\n",
        "            gnb.fit(X_train, y_train)\n",
        "        \n",
        "            # Make predictions and calculate AUC\n",
        "            y_pred = gnb.predict_proba(X_test)[:, 1]\n",
        "            auc = roc_auc_score(y_test, y_pred)\n",
        "        \n",
        "            # Check if the current AUC is higher than the optimal AUC\n",
        "            if auc > optimal_auc:\n",
        "                optimal_auc = auc\n",
        "                optimal_lower_limit = lower_limit\n",
        "                optimal_upper_limit = upper_limit\n",
        "    \n",
        "    # Store the optimal limits for the current column\n",
        "    optimal_limits[column] = (optimal_lower_limit, optimal_upper_limit)\n",
        "\n",
        "# Print the optimal limits for each column\n",
        "for column, (lower_limit, upper_limit) in optimal_limits.items():\n",
        "    print(f\"Optimal limits for column '{column}': Lower Limit = {lower_limit}, Upper Limit = {upper_limit}\")\n",
        "\n",
        "# Print the overall optimal AUC score\n",
        "print(\"Optimal AUC:\", optimal_auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_1BirvUjwPx",
        "outputId": "d1b55ea7-d963-487d-8109-043b6f1fadce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal limits for column 'age': Lower Limit = 0.05, Upper Limit = 0\n",
            "Optimal limits for column 'cigsPerDay': Lower Limit = 0.7, Upper Limit = 0.01\n",
            "Optimal limits for column 'totChol': Lower Limit = 0, Upper Limit = 0\n",
            "Optimal limits for column 'BMI': Lower Limit = 0, Upper Limit = 0.95\n",
            "Optimal limits for column 'heartRate': Lower Limit = 0, Upper Limit = 0\n",
            "Optimal limits for column 'glucose': Lower Limit = 0.95, Upper Limit = 0\n",
            "Optimal limits for column 'mean_BP': Lower Limit = 0, Upper Limit = 0\n",
            "Optimal limits for column 'sex_M': Lower Limit = 0, Upper Limit = 0\n",
            "Optimal limits for column 'BPMeds_1.0': Lower Limit = 0, Upper Limit = 0\n",
            "Optimal limits for column 'prevalentHyp_1': Lower Limit = 0, Upper Limit = 0.4\n",
            "Optimal limits for column 'diabetes_1': Lower Limit = 0, Upper Limit = 0\n",
            "Optimal AUC: 0.7320274599542334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/ml1_final_project/data_cardiovascular_risk.csv')\n",
        "columns_to_convert = ['sex', 'education', 'is_smoking', 'BPMeds', 'prevalentStroke', 'prevalentHyp', 'diabetes', 'TenYearCHD']\n",
        "df[columns_to_convert] = df[columns_to_convert].astype('object')\n",
        "categorical_columns = df.select_dtypes(include='object').columns\n",
        "numerical_columns = df.select_dtypes(include=['float', 'int']).columns\n",
        "\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "# Remove rows where 'bpmeds' column is null\n",
        "df = df.dropna(subset=['BPMeds'])\n",
        "\n",
        "imputing_median1 = df[df['is_smoking'] == 'YES']['cigsPerDay'].median()\n",
        "df['cigsPerDay'] = df['cigsPerDay'].fillna(imputing_median1)\n",
        "\n",
        "df.drop('id', axis=1, inplace=True)\n",
        "df.drop('education', axis=1, inplace=True)\n",
        "df.drop(['is_smoking', 'prevalentStroke'], axis=1, inplace=True)\n",
        "\n",
        "for var in ['totChol', 'BMI', 'heartRate']:\n",
        "  imputer = IterativeImputer(random_state=0)\n",
        "  df[[var]] = imputer.fit_transform(df[[var]])\n",
        "\n",
        "\n",
        "# fit and transform the imputer on your data\n",
        "imputer = IterativeImputer(random_state = 0)\n",
        "imputer.fit(df[['glucose']])\n",
        "\n",
        "df[['glucose']] = imputer.transform(df[['glucose']])\n",
        "\n",
        "\n",
        "##### New Feature meanBP\n",
        "# Create a new feature 'mean_BP' as the mean of 'sysBP' and 'diaBP'\n",
        "df['mean_BP'] = (df['sysBP'] + df['diaBP']) / 2\n",
        "\n",
        "# Drop the 'sysBP' and 'diaBP' columns\n",
        "df.drop(['sysBP', 'diaBP'], axis=1, inplace=True)\n",
        "###########\n",
        "\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "X = df.drop(['TenYearCHD_1'], axis = 1)\n",
        "y = df['TenYearCHD_1']\n",
        "\n",
        "X_winsorized = X.copy()\n",
        "\n",
        "\n",
        "# Apply winsorization to each column with the optimal limits\n",
        "X_winsorized = X.copy()\n",
        "\n",
        "X_winsorized['age'] = winsorize(X_winsorized['age'], limits=(0, 0))\n",
        "X_winsorized['cigsPerDay'] = winsorize(X_winsorized['cigsPerDay'], limits=(0.7, 0.01))\n",
        "X_winsorized['totChol'] = winsorize(X_winsorized['totChol'], limits=(0, 0))\n",
        "# X_winsorized['sysBP'] = winsorize(X_winsorized['sysBP'], limits=(0, 0))\n",
        "# X_winsorized['diaBP'] = winsorize(X_winsorized['diaBP'], limits=(0.8, 0))\n",
        "X_winsorized['mean_BP'] = winsorize(X_winsorized['mean_BP'], limits=(0, 0))\n",
        "X_winsorized['BMI'] = winsorize(X_winsorized['BMI'], limits=(0, 0))\n",
        "X_winsorized['heartRate'] = winsorize(X_winsorized['heartRate'], limits=(0, 0))\n",
        "X_winsorized['glucose'] = winsorize(X_winsorized['glucose'], limits=(0.7, 0.2))\n",
        "X_winsorized['sex_M'] = winsorize(X_winsorized['sex_M'], limits=(0, 0))\n",
        "X_winsorized['BPMeds_1.0'] = winsorize(X_winsorized['BPMeds_1.0'], limits=(0, 0))\n",
        "X_winsorized['prevalentHyp_1'] = winsorize(X_winsorized['prevalentHyp_1'], limits=(0, 0.4))\n",
        "X_winsorized['diabetes_1'] = winsorize(X_winsorized['diabetes_1'], limits=(0, 0))\n",
        "\n",
        "# Split the winsorized data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_winsorized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train_s = scaler.fit_transform(X_train)\n",
        "X_test_s = scaler.transform(X_test)\n",
        "\n",
        "# Train Gaussian Naive Bayes\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train_s, y_train)\n",
        "\n",
        "# Make predictions and calculate AUC\n",
        "y_pred = gnb.predict_proba(X_test_s)[:, 1]\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "# Print the AUC score\n",
        "print(\"AUC:\", auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu71zyMNkFjp",
        "outputId": "774c84cd-f2c2-4b56-f073-a89efe0e23d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: 0.7465812356979405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_winsorized.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3NbZtDMk1jY",
        "outputId": "1f873bda-3ce1-4abd-ae13-444944e54677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3346, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_winsorized.shape, y.shape)"
      ],
      "metadata": {
        "id": "h4yg-2rem1Xy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21c080fc-b84a-4718-90a4-15af69e6485f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3346, 11) (3346,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_winsorized.reset_index(drop=True, inplace=True)\n",
        "y.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "OKMCmXxtiy7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df = pd.concat([X_winsorized, y], axis=1)"
      ],
      "metadata": {
        "id": "dqoD0YBMi-7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LGI57SqjDUF",
        "outputId": "aa10bf75-8cf6-4844-f8ca-e6e360b54682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3346, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df.to_csv('Best_dataset2.csv', index=False)"
      ],
      "metadata": {
        "id": "XWgOBZ4yjFfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oh6KyTWZjNBV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}